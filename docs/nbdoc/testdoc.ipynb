{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Steppy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more tests for existing Steppy Transforms, and other supporting code is a great method to familiarize yourself and make your starting contributions to the Steppy project. \n",
    "\n",
    "Also,it will be not be possible for your contributed code to be merged into the master Steppy repo without accompanying unit tests that provide coverage for the critical parts of your contribution. \n",
    "\n",
    "You can expect your contribution to not past review unless tests are provided to cover edge cases and test for error conditions. Remember, you are asking people to use your contributed code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steppy Test Guidelines\n",
    "\n",
    "Some of these guidelines have been adapted from [here](https://docs.python-guide.org/writing/tests/) and [here.](https://github.com/pandas-dev/pandas/wiki/Testing)\n",
    "\n",
    "\n",
    "\n",
    "- (RECCOMENED) Learn your tools and learn how to run a single test or a test case. Then, when developing a function inside a module, run this function’s tests frequently, ideally automatically when you save the code.\n",
    "\n",
    "- (REQUIRED) Each test unit must be fully independent. Each test must be able to run alone, and also within the test suite, regardless of the order that they are called. The implication of this rule is that each test must be loaded with a fresh dataset and may have to do some cleanup afterwards. This standard is that this is handled by setUp() and tearDown() methods.\n",
    "\n",
    "- (REQUIRED) implement a hook that runs all tests before pushing code to a shared repository.\n",
    "\n",
    "- (REQUIRED) Do not test that something raises Exception, because that tends to mask a lot of errors. For example, if a function's signature changes between releases, you could be catching the wrong kind of error altogether. Going forward, the goal is to have no test cases that pass if Exception or a subclass is raised (we're not quite there yet).\n",
    "\n",
    "- (RECCOMENED) Run the full test suite before a coding session, and run it again after.\n",
    "\n",
    "- (RECCOMENED) The first step when you are debugging your code is to write a new test pinpointing the bug. While it is not always possible to do, those bug catching tests are among the most valuable pieces of code in your project.\n",
    "\n",
    "- (RECCOMENED) Use long and descriptive names for testing functions. These function names are displayed when a test fails, and should be as descriptive as possible.\n",
    "\n",
    "- (REQIRED) When something goes wrong or has to be changed, and if your code has a good set of tests, you or other maintainers will rely largely on the testing suite to fix the problem or modify a given behavior. Therefore the testing code will be read as much as or even more than the running code. \n",
    "\n",
    "- (RECCOMENED) Testing code is as an introduction to any developers. When someone will have to work on the code base, running and reading the related testing code is often the best thing that they can do to start. They will or should discover the hot spots, where most difficulties arise, and the corner cases. If they have to add some functionality, the first step should be to add a test to ensure that the new functionality is not already a working path that has not been plugged into the interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Explicit Exception Testing\n",
    "\n",
    "Use ``assertRaisesRegex`` from ``pandas.util.testin``. It lets you be very explicit with what you expect (and prevents hiding errors like changing signatures, etc.)\n",
    "\n",
    "with: \n",
    "\n",
    "    tm.assertRaises(ValueError)\n",
    "    raise ValueError(\"an error\")\n",
    "    \n",
    "with:\n",
    "\n",
    "    tm.assertRaisesRegexp(TypeError, 'invalid literal'):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a testing environment\n",
    "\n",
    "We recommend you create a virtual environment for your testing. Use your favorite tool to create a virtual environment. \n",
    "\n",
    "Create a virtual environment /STEPPY-TEST (you can substitute a different name than STEPPY-TEST,ifyou wish.):\n",
    "\n",
    "    >>> python -m venv ../STEPPY-TEST\n",
    "    \n",
    "Use or ACTIVATE the virtual environment named STEPPY-TEST:\n",
    "\n",
    "    >>> source ../STEPPY-TEST/bin/activate\n",
    "    \n",
    "install the packages you will need to develop test for Steppy. The following are the standard packages we use:\n",
    "\n",
    "    (STEPPY-TEST)>>> pip install steppy \n",
    "    (STEPPY-TEST)>>> pip install nose  \n",
    "    (STEPPY-TEST)>>> pip install unittest\n",
    "    (STEPPY-TEST)>>> pip install pytest\n",
    "    (STEPPY-TEST)>>> pip install pandas\n",
    "    (STEPPY-TEST)>>> pip install coverage\n",
    "    \n",
    "You may already have pandas as part of your environment. What you will need to import into python is:\n",
    "\n",
    "    import nose\n",
    "    import unittest\n",
    "    import pytest\n",
    "    import pandas.util.testing as tm\n",
    "    # steppy imports\n",
    "    from steppy.base import Step, BaseTransformer, make_transformer\n",
    "    from steppy.adapter import Adapter, E\n",
    "    from steppy.utils import get_logger\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Resources\n",
    "\n",
    "- https://docs.python-guide.org/writing/tests/\n",
    "- https://semaphoreci.com/community/tutorials/testing-python-applications-with-pytest\n",
    "- http://pythontesting.net/framework/nose/nose-introduction/\n",
    "- https://ymichael.com/2014/12/17/python-testing-with-nose-for-beginners.html\n",
    "- https://github.com/pandas-dev/pandas/wiki/Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage tool for Steppy\n",
    "\n",
    "Coverage measurement is typically used to measure the effectiveness of tests. It can show which parts of your code are being exercised by tests, and which are not. You can use any coverage tool you wish. We recommend\n",
    "\n",
    "    Coverage.py (see documentation for installation and usage) \n",
    "    \n",
    ",a tool for measuring code coverage of Python programs. It monitors your test suite, noting which parts of the code have been executed, then analyzes the source to identify code that could have been executed but was not.\n",
    "\n",
    "Also a good introduction to Coverage.py is:\n",
    "\n",
    "    https://www.blog.pythonlibrary.org/2016/07/20/an-intro-to-coverage-py/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage of Coverage\n",
    "\n",
    "This section shows **Coverage** examples. It assume you are using the installed **Coverage** package You can substitute below examples with a different coverage tool,should you wish.\n",
    "\n",
    "    ./python -m coverage\n",
    "\n",
    "To run the test suite under coverage.py, do the following:\n",
    "\n",
    "./python COVERAGEDIR run --pylib Lib/test/regrtest.py\n",
    "To run only a single test, specify the module/package being tested in the --source flag (so as to prune the coverage reporting to only the module/package you are interested in) and then append the name of the test you wish to run to the command:\n",
    "\n",
    "./python COVERAGEDIR run --pylib --source=abc Lib/test/regrtest.py test_abc\n",
    "To see the results of the coverage run, you can view a text-based report with:\n",
    "\n",
    "./python COVERAGEDIR report\n",
    "You can use the --show-missing flag to get a list of lines that were not executed:\n",
    "\n",
    "./python COVERAGEDIR report --show-missing\n",
    "But one of the strengths of coverage.py is its HTML-based reports which let you visually see what lines of code were not tested:\n",
    "\n",
    "./python COVERAGEDIR html -i --include=`pwd`/Lib/* --omit=\"Lib/test/*,Lib/*/tests/*\"\n",
    "This will generate an HTML report in a directory named htmlcov which ignores any errors that may arise and ignores modules for which test coverage is unimportant (e.g. tests, temp files, etc.). You can then open the htmlcov/index.html file in a web browser to view the coverage results along with pages that visibly show what lines of code were or were not executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Coverage\n",
    "It should be noted that a quirk of running coverage over Python’s own stdlib is that certain modules are imported as part of interpreter startup. Those modules required by Python itself will not be viewed as executed by the coverage tools and thus look like they have very poor coverage (e.g., the stat module). In these instances the module will appear to not have any coverage of global statements but will have proper coverage of local statements (e.g., function definitions will be not be traced, but the function bodies will). Calculating the coverage of modules in this situation will simply require manually looking at what local statements were not executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Branch Coverage\n",
    "For the truly daring, you can use another powerful feature of coverage.py: branch coverage. Testing every possible branch path through code, while a great goal to strive for, is a secondary goal to getting 100% line coverage for the entire stdlib (for now).\n",
    "\n",
    "If you decide you want to try to improve branch coverage, simply add the --branch flag to your coverage run:\n",
    "\n",
    "    /python COVERAGEDIR run --pylib --branch <arguments to run test(s)>\n",
    "    \n",
    "This will lead to the report stating not only what lines were not covered, but also what branch paths were not executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filing the Issue\n",
    "\n",
    "Once you have increased coverage, you need to create an issue on the issue tracker and submit a pull request. On the issue set the “Components” to “Test” and “Versions” to the version of Python you worked on (i.e., the in-development version)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
