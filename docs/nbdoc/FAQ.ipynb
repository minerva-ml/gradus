{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. toctree::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Steppy standard documentation framework?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation framework is **Sphinx**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between scikit pipeline and steppy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a  pipeline a series of data-operations are connected together. In a data-analytics problem, this is usually a left-to-right series of calls of transformer calls ended by an estimator, that is a PIPELINE of invocations.\n",
    "\n",
    "The major limitation the scikit learn Pipeline wrapper is that passed data object must be same input and output, i.e. data object(s) is(are) same and implicit thoughout Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus step introduces two new wrappers, Step and Adapter to avoid these limitations:\n",
    "\n",
    "Steps communicate data between each other with **Adapters**, which are implemented as Python dictionaries. This makes it possible to pass collections of arbitrary data types (Numpy arrays, Pandas dataframes, etc.). The basic structure is as follows:\n",
    "\n",
    "    data_train = {'input':\n",
    "                    {\n",
    "                         'X': X_train,\n",
    "                         'y': y_train,\n",
    "                    }\n",
    "                }\n",
    "\n",
    "where X_train,y_train are local data objects, X,y are names of arguments to step-exec-object-instance and  ‘input'  is the name of the Adapter.\n",
    "\n",
    "\n",
    "see https://github.com/neptune-ml/steppy-examples/blob/master/tutorials/1-getting-started.ipynb for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## receiving an error \"no module named deepsense\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the repository folder do: \n",
    "\n",
    "    pip3 install -r requirements.txt \n",
    "    \n",
    "this should solve this error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to get around  xp =f(x)  to, x,xp = f(x) challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the argument/inputs of ALL step-exec-object-instance must be covered by the named Adapter, but all the named arguments of the named Adapter need not be used by the step-exec-object-instance. For example the following Adapter would work for a **Step** that needs only X .\n",
    "\n",
    "\n",
    "    data_train = {'input':\n",
    "                    {\n",
    "            'X': X_train,\n",
    "            'y': y_train,\n",
    "            ‘z1’, some_other_bound_variable,\n",
    "            ‘etc’, etc\t\n",
    "                    }\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Are there other Resources for Steepy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Yes. see  https://steppy.readthedocs.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Are there tutorials for Steepy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Yes. In the form of notebooks. See https://github.com/neptune-ml/steppy-examples/tree/master/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Is Steppy Threadsafe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Steppy itself is  thread-safe. However, you will use Steppy with many other packages which may not be thread-safe. For example, numpy is thread-safe.\n",
    "ndarrays can be accessed in a thread-safe manner, but you must be careful with state if you mutate an array.\n",
    "\n",
    "In Pandas, deleting a column is usually not thread-safe as changing the size of a DataFrame usually results in a new Dataframe object. At some point this may change in Pandas and other python libaries as multi-cored CPUs are becoming common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from open-solution-data-science-bowl-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q&A from Home Credit Default Risk (Open souce solution for Kaggle)\n",
    "\n",
    "August-2018\n",
    "\n",
    "Dear Kagglers,\n",
    "\n",
    "As you well know we share our work with the community for the benefit of all. We want to help those who are learning the ropes of data science get in the groove of things, we want to help those less organized make their code and process cleaner and finally we want those at the very top of the game to use our work (or parts of it) to develop state of the art solutions quicker and test the boundaries of what is possible for a given problem.\n",
    "...\n",
    "\n",
    "Let me just clarify that we work with Python3.5 and Ubuntu 16.04. We did not run any tests on other operating systems and we do not use Python3.6.\n",
    "\n",
    "Also, please make sure that you are 100% compliant with our requirements.txt file. Differences in packages versions may lead to unexpected results :)\n",
    "\n",
    "@starhao note that sometimes groupby operation yields empty array. Because of that, you are receiving warning you mentioned. It is ok, your experiment progress.\n",
    "\n",
    "Finally, let me mention that end-to-end execution is something like 10-12h. Hence, indeed you may wait some time for the features to get computed. It happens here Step installment_payments_hand_crafted, fitting and transforming... \n",
    "\n",
    "(Ed: Also runs in approximately 3. hours in the following configuration:\n",
    "\n",
    "    Model Name:\tMac Pro\n",
    "    OS: High Sierra, version.10.6.13\n",
    "    Processor Name:\t12-Core Intel Xeon E5\n",
    "    Processor Speed:\t2.7 GHz\n",
    "    Total Number of Cores:\t12\n",
    "    L2 Cache (per Core):\t256 KB\n",
    "    L3 Cache:\t30 MB\n",
    "    Memory:\t64 GB\n",
    ")\n",
    "\n",
    "It heavily depends on your hardware. In this topic, some people mentioned their hardware configuration and time it took. It can be even hours, in case you have just few vCPUs.\n",
    "\n",
    ":Authors: Kuba & Kamil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Is is possible to save features with your pipeline? \n",
    "I mean raw features, for train and test set, in the exact same shape as you feed them to your model?\n",
    "\n",
    ":Author: narsil (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Steppy Step object is designed to handle stuff like this. There are 3 flags that are particularly important to your problem:\n",
    "\n",
    "    persist_output = True\n",
    "    cache_output = True\n",
    "    load_persisted_output = False\n",
    "    \n",
    "In our case the Step that joins the features is called feature_joiner so go to this line and setup persist_output=True both during training and evaluation.\n",
    "\n",
    "Then you need to generate the features. I would suggest you do it in one go with something like this:\n",
    "\n",
    "    neptune run --config configs/neptune.yaml main.py train --pipeline_name lightGBM\n",
    "\n",
    "it will dump your features in the /YOUR_EXPERIMENT/outputs directory.\n",
    "\n",
    "Everything can be loaded with \n",
    "\n",
    "    sklearn.externals.joblib.load(filepath)\n",
    "\n",
    "The same thing can be done for the test set. Just run\n",
    "\n",
    "    neptune run --config configs/neptune.yaml main.py predict --pipeline_name lightGBM\n",
    "\n",
    "Now with our code we divide train/valid by default so if you want to have the entire train features and not train/valid you need to go to the pipeline_manager and change\n",
    "\n",
    "    train_data = {'application': {'X': train_data_split.drop(cfg.TARGET_COLUMNS, axis=1),\n",
    "                                  'y': train_data_split[cfg.TARGET_COLUMNS].values.reshape(-1),\n",
    "                                  'X_valid': valid_data_split.drop(cfg.TARGET_COLUMNS, axis=1),\n",
    "                                  'y_valid': valid_data_split[cfg.TARGET_COLUMNS].values.reshape(-1)\n",
    "                                  },\n",
    "to this\n",
    "\n",
    "    train_data = {'application': {'X': tables.application_train.drop(cfg.TARGET_COLUMNS, axis=1),\n",
    "                                  'y': tables.application_train[cfg.TARGET_COLUMNS].values.reshape(-1),\n",
    "                                  'X_valid':None,\n",
    "                                  'y_valid': None\n",
    "                                  },\n",
    "                                  \n",
    "It will most likely fail at training (because we need X_valid, y_valid) but is should generate the features correctly. If you have any trouble please let me know.\n",
    "\n",
    "\n",
    ":Author: Jakub Czakon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  how do I convert a saved feature file into a dataframe\n",
    "\n",
    ":Author: incarnation (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "You can get data frame with all features by following code:\n",
    "\n",
    "    from sklearn.externals import joblib\n",
    "    df = joblib.load('path/to/your/feature_joiner')['features']\n",
    "\n",
    ":Author: Miłosz Michta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##  Is the script in your repo by default use single cpu for model training? If yes, where to change the setting in your project to use multiple cpus?\n",
    "\n",
    "Also,for example, the machine has 16 cpus, and if I want to use 8 cpu for the lgb modeling (I'd like to reserve the other 8 cpus for other tasks), how should I configure the setting in the project? Would setting \"num_works=16\", and \"lgbm__nthread: 8\" (in lgb parameters) be the correct configuration in such a case?\n",
    "\n",
    "\n",
    ":Author: Shize Su (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Have you tried to change num_workers in neptune.yaml? By default it's setted to 1.\n",
    "\n",
    "Also, If you want to run your training on 8 cpus, set num_workers: 8. The amount of your total cpu number doesn't matter.\n",
    "\n",
    "(Ed: One cavet, is that most of the multi-cpu/core architectures, support 2 or more threads per cpu/core.  num_workers: should be set to thread count.  For example, Intel Core i7-7700K has 4 cores and 8 parellel threads.)\n",
    "\n",
    ":Author: Miłosz Michta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Where could we set (/change) the random seed for the kfold split? I didn't find random seed setting in the neptune.yaml file.\n",
    "\n",
    " :Author: Shize Su (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "There is only one global random seed in pipeline_config.py: \n",
    "\n",
    "    RANDOM_SEED = 90210\n",
    "    \n",
    "To change random seed for only k-fold split, you can do this manually in pipeline_manager.py in _get_fold_generator function.\n",
    "\n",
    ":Author: Miłosz Michta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## I change some lgb parameters in the neptune.yaml file and rerun the code. \n",
    "\n",
    "Then a weird error in model training raised up as follows:\n",
    "\n",
    "    2018-08-21 17-13-18 home-credit >>> LightGBM, train data shape (48744, 1174)\n",
    "\n",
    "    2018-08-21 17-13-18 home-credit >>> LightGBM, validation data shape (61503, 1174)\n",
    "\n",
    "    2018-08-21 17-13-18 home-credit >>> LightGBM, train labels shape (246008,)\n",
    "\n",
    "    2018-08-21 17-13-18 home-credit >>> LightGBM, validation labels shape (61503,)\n",
    "\n",
    "    [LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
    "\n",
    "    [LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
    "\n",
    "And obviously the train data and train label shape doesn't match and error raised up when start model training. It seems that the code read the saved test feature data as train feature data which caused such error when rerunning the code. But I don't know why this could happen. Is that by default the code saved test feature data with the same file name as the train feature data and override it? To avoid such errors in rerunning the code (with different lgb parameters), are there anywhere in the project setting that I need to change?\n",
    "\n",
    "Note that I run the code exactly as it is, except that I follow Jakub's suggestion below to setup persist_output=True in the feature_joiner before using the following command to run the code:\n",
    "\n",
    "    python main.py -- train_evaluate_predict_cv --pipeline_name lightGBM\n",
    "\n",
    "Thanks in advance!\n",
    "\n",
    "Update: I checked the saved feature data files and verified that the saved train feature data files are indeed override by the saved test feature data files (they have the same file name \"feature_joiner_fold_x\"). @Milosz, would you mind letting me know which setting in the project code I should change to avoid such feature files overriding issue? Thanks!\n",
    "\n",
    ":Author: incarnation (Kaggle handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "\n",
    "There are 3 flags in the Step constructor that you need to consider:\n",
    "\n",
    "persist_output: True\n",
    "load_persisted_output: True\n",
    "cache_output: True\n",
    "If you don't want to ovewrite anything during eval/test just make sure to set perist_output: False . All the steps used are defined in the pipeline_blocks.py . More specifically you need to take care of the feature_joiner .\n",
    "\n",
    "It is also important to know that you can have a seperate experiment_dir for train and test so that you could just load your transformed features but change the classifier on top of it. In that case you would need to copy the experiment_dir/transformers to a new experiment directory. Also make sure to specify 'clean_experiment_directory_before_training: 0 in the neptune.yaml otherwise it will just remove everything from the experiment_dir . One last piece of the puzzle if you want to be steppy master is that if you have your lgbm trained in that folder steppy will simply load that model and transform it unless you pass force_fitting: True to the Step contractor for that step. Which means that running grid search or random search or simply retraining with different hyperparams you don't have to remove that lgbm transformer from experiment_dir/transformers but you can simply pass that flag and overwrite it.\n",
    "\n",
    ":Author: Jakub Czakon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## I wanted to try some sklearn models and did not get it running. \n",
    "\n",
    "    python main.py -- train_evaluate_predict --pipeline_name random_forest\n",
    "\n",
    "it will give me an error:\n",
    "\n",
    "    pipeline = PIPELINES[pipeline_name](config=cfg.SOLUTION_CONFIG, train_mode=True) TypeError: 'dict' object is not callable\n",
    "\n",
    "For me, this seems to be quite natural, as the sklearn models are defined as dictionaries with keys \"train\" and \"inference\" in the pipelines.py as opposed to the lgbm model.\n",
    "\n",
    "Any tips would be much appreciated!\n",
    "\n",
    ":Author: Maximilian Hahn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "You're right, to solve this you can simply change that:\n",
    "\n",
    "    'random_forest': {'train': partial(sklearn_main,\n",
    "                                            ClassifierClass=RandomForestClassifier,\n",
    "                                            clf_name='random_forest',\n",
    "                                            train_mode=True),\n",
    "                     'inference': partial(sklearn_main,\n",
    "                                                ClassifierClass=RandomForestClassifier,\n",
    "                                                clf_name='random_forest',\n",
    "                                                train_mode=False)\n",
    "                    }\n",
    "to this:\n",
    "\n",
    "    'random_forest': partial(sklearn_main,\n",
    "                         ClassifierClass=RandomForestClassifier,\n",
    "                         clf_name='random_forest'),\n",
    "\n",
    ":Author: Miłosz Michta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## is there a way to run it using Jupyter?\n",
    "\n",
    ":Author: Daniel Burrueco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "If you are doing it in python.\n",
    "\n",
    "    !python main.py -- train_evaluate_predict_cv --pipeline_name lightGBM\n",
    "\n",
    ":Author: William Green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "What is being executed are pipelines from main.py. In practice in means that you can create notebook in the repository root, import required libs and execute one of these pipelines.\n",
    "\n",
    "For example training pipeline is defined in the pipeline_manager.py file. Just make sure that you put correct paths to data.\n",
    "\n",
    ":Author: Kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  I run out of disk space. Is it possible to run with the cache turned off?\n",
    "\n",
    ":Author: Dromosys (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Set \n",
    "\n",
    "    cache_output=False\n",
    "    persist_output=False \n",
    "    load_persisted_output=False \n",
    "    \n",
    "in pipelines.py and pipeline_blocks.py\n",
    "\n",
    ":Author: Jakub Czakon (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  It looks like the script was designed to run on neptune only. I don't see the difference between Fast Track and Step by step installation guide.\n",
    "\n",
    ":Author: nlgn (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "Our code in neptune-agnostic, thus you can run it as Python script:\n",
    "\n",
    "    python main.py train_evaluate_predict --pipeline_name lightGBM.\n",
    "\n",
    "Full list of pipelines is here: lightGBM, XGBoost, random_forest, log_reg, svc. I'm still playing with XGBoost.\n",
    "\n",
    "My intention for Fast Track was to give three short points for User who can clone repo, install reqs, etc.\n",
    "\n",
    "\n",
    ":Author: kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Could you point me the right class structure and method names where to find save and load fold data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "If you want to simply read them in go:\n",
    "\n",
    "    from sklearn.externals import joblib\n",
    "    feature_dict = joblib.load('PATH/TO/FEATURE_JOINER/')\n",
    "    fetures = feature_dict['features']\n",
    "\n",
    ":Author: Jakub Czakon (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Is it possible to save target values via feature_joiner feature_joiner_valid while using cv? Or How can access cv target values and store?\n",
    "\n",
    ":Author: kkaczmarek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "You can adjust FeatureJoiner to do that:\n",
    "\n",
    "    class FeatureJoiner(BaseTransformer):\n",
    "    def __init__(self, use_nan_count=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.use_nan_count = use_nan_count\n",
    "\n",
    "    def transform(self, numerical_feature_list, categorical_feature_list, targets, **kwargs):\n",
    "        features = numerical_feature_list + categorical_feature_list\n",
    "        for feature in features:\n",
    "            feature.reset_index(drop=True, inplace=True)\n",
    "        features = pd.concat(features, axis=1).astype(np.float32)\n",
    "        if self.use_nan_count:\n",
    "            features['nan_count'] = features.isnull().sum(axis=1)\n",
    "\n",
    "        outputs = dict()\n",
    "        outputs['features'] = features\n",
    "        outputs['feature_names'] = list(features.columns)\n",
    "        outputs['categorical_features'] = self._get_feature_names(categorical_feature_list)\n",
    "        outputs['targets'] = targets\n",
    "        return outputs\n",
    "\n",
    "    def _get_feature_names(self, dataframes):\n",
    "        feature_names = []\n",
    "        for dataframe in dataframes:\n",
    "            try:\n",
    "                feature_names.extend(list(dataframe.columns))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                feature_names.append(dataframe.name)\n",
    "\n",
    "        return feature_names\n",
    "        \n",
    "Remember to change the pipeline_blocks accordingly.\n",
    "\n",
    "If you want it just for the adhoc purposes however I would simply dump the targets with _foldX suffix through pipeline_manager.py . For example:\n",
    "\n",
    "    for fold_id, (train_idx, valid_idx) in enumerate(fold_generator):\n",
    "    (train_data_split,\n",
    "     valid_data_split) = tables.application_train.iloc[train_idx], tables.application_train.iloc[valid_idx]\n",
    "\n",
    "     joblib.dump(train_data_split[cfg.TARGET_COLUMNS], 'train_target_fold_{}'.format(fold_id))\n",
    "\n",
    ":Author: Jakub Czakon (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  I am wondering: after running the code, where can I find the output, I mean, 'submission.csv'?\n",
    "\n",
    ":Author:  DKADKA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "It is placed in the experiment_directory that you specified in the yaml file.\n",
    "\n",
    ":Author: Kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  When I run any of the functions that include parallel apply the function gets hung up and does not move?\n",
    "\n",
    ":Author: benedic2 (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "I observed this effect for other versions of Pandas:\n",
    "\n",
    "1. make sure that you have version listed in the requirements file.\n",
    "1. Check CPU and memory utilization. Very likely everything is just fine. It just takes some time to extract features from files.\n",
    "1. If you are sure that you have issues with multiprocessing you can roll back to the standard Pandas. In such case you do not use parallel apply function. You simply change it to the operation on Pandas' group object. So something like groupobject.apply(func).reset_index(). This will do the same but with Pandas.\n",
    "\n",
    ":Author: kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Is the number of estimators set anywhere for the LGBM models?\n",
    "\n",
    ":Author: benedic2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Yes, we set it in the configuration files. Look for lgbm__number_boosting_rounds. \n",
    "\n",
    ":Author: kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## I saw you were using SHAP values to evaluate feature importance. How do you go about removing unimportant features? Do you remove simply remove all features with SHAP values below a certain threshold??\n",
    "\n",
    ":Author: IINewton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Actually, we are not removing any features. This could be really problematic. Take a look, that in our notebook we analyze data/model from fold_0 and features which have zero importance in this fold also have nonzero importance in others.\n",
    "\n",
    ":Author: Miłosz Michta (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## from toolkit.sklearn_transformers.models import SklearnClassifier ModuleNotFoundError: No module named 'toolkit'\n",
    "\n",
    ":Author: Omid Safarzadeh (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "I think that you did not install steppy-toolkit==0.1.5. try this: \n",
    "\n",
    "    pip3 install steppy-toolkit==0.1.5.\n",
    "\n",
    ":Author: kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Is the command same for training after making adjustments to the parameters? Or, can I just run: -- train_evaluate_predict_cv command ? Just wondering if I have to go through the pipeline again.?\n",
    "\n",
    ":Author: William Green (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    " \n",
    "Remember to change the clean_experiment_directory in the neptune.yaml to False and force_fitting=True in the lightgbm Step. Having done that running it again will just load the features for each fold and train model on top of it.\n",
    "\n",
    ":Author: Jakub Czakon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q&A from TGS Salt Identification Challenge  (Open souce solution for Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Goals\n",
    "\n",
    "- establish solid benchmark for the competition,\n",
    "- make this competition more approachable by giving starter code and providing help via discussion forum, promote the idea of clean and extensible code for Kaggle competitions :) \n",
    "- In this topic... you will read about open solution updates, new ideas, experiments and comments. Feel invited to participate in building this.\n",
    "\n",
    "Have fun competing :) \n",
    "\n",
    ":Authors: Kuba & Kamil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## I got this error: File \"open-solution-salt-identification-master/common_blocks/callbacks.py\",\n",
    "\n",
    "    line 150, in on_batch_end loss = loss.data.cpu().numpy()[0] IndexError: too many indices for array \n",
    "    \n",
    "Could you give me some help? \n",
    "  \n",
    " :Author: tommao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Please make sure that you have torch==0.3.1. On the more general level, please make sure that you have all requirements is place: requirements.txt.\n",
    "\n",
    ":Author: Kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q&A from open-solution-ship-detection\n",
    "https://github.com/neptune-ml/open-solution-ship-detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from open-solution-value-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from open-solution-googleai-object-detection\n",
    "https://github.com/neptune-ml/open-solution-googleai-object-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from Mapping Challenge\n",
    "https://www.crowdai.org/challenges/mapping-challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from open-solution-value-prediction\n",
    "https://github.com/neptune-ml/open-solution-value-prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from open-solution-cdiscount-starter\n",
    "https://github.com/neptune-ml/open-solution-cdiscount-starter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from open-solution-talking-data\n",
    "https://github.com/neptune-ml/open-solution-talking-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from open-solution-avito-demand-prediction\n",
    "https://github.com/neptune-ml/open-solution-avito-demand-prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A from open-solution-toxic-comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "62px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
