{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. toctree::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Steppy standard documentation framework?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation framework is **Sphinx**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the difference between scikit pipeline and steppy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a  pipeline a series of data-operations are connected together. In a data-analytics problem, this is usually a left-to-right series of calls of transformer calls ended by an estimator, that is a PIPELINE of invocations.\n",
    "\n",
    "The major limitation the scikit learn Pipeline wrapper is that passed data object must be same input and output, i.e. data object(s) is(are) same and implicit thoughout Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus step introduces two new wrappers, Step and Adapter to avoid these limitations:\n",
    "\n",
    "Steps communicate data between each other with **Adapters**, which are implemented as Python dictionaries. This makes it possible to pass collections of arbitrary data types (Numpy arrays, Pandas dataframes, etc.). The basic structure is as follows:\n",
    "\n",
    "    data_train = {'input':\n",
    "                    {\n",
    "                         'X': X_train,\n",
    "                         'y': y_train,\n",
    "                    }\n",
    "                }\n",
    "\n",
    "where X_train,y_train are local data objects, X,y are names of arguments to step-exec-object-instance and  ‘input'  is the name of the Adapter.\n",
    "\n",
    "\n",
    "see https://github.com/neptune-ml/steppy-examples/blob/master/tutorials/1-getting-started.ipynb for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error \"no module named deepsense\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the repository folder do: \n",
    "\n",
    "    pip3 install -r requirements.txt \n",
    "    \n",
    "this should solve this error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to get around  xp =f(x)  to, x,xp = f(x) challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "All of the argument/inputs of ALL step-exec-object-instance must be covered by the named Adapter, but all the named arguments of the named Adapter need not be used by the step-exec-object-instance. For example the following Adapter would work for a **Step** that needs only X .\n",
    "\n",
    "\n",
    "    data_train = {'input':\n",
    "                    {\n",
    "            'X': X_train,\n",
    "            'y': y_train,\n",
    "            ‘z1’, some_other_bound_variable,\n",
    "            ‘etc’, etc\t\n",
    "                    }\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Are there other Resources for Steepy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Yes. see  https://steppy.readthedocs.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Are there tutorials for Steepy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Yes. In the form of notebooks. See https://github.com/neptune-ml/steppy-examples/tree/master/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Is Steppy Threadsafe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Steppy itself is  thread-safe. However, you will use Steppy with many other packages which may not be thread-safe. For example, numpy is thread-safe.\n",
    "ndarrays can be accessed in a thread-safe manner, but you must be careful with state if you mutate an array.\n",
    "\n",
    "In Pandas, deleting a column is usually not thread-safe as changing the size of a DataFrame usually results in a new Dataframe object. At some point this may change in Pandas and other python libaries as multi-cored CPUs are becoming common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-data-science-bowl-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from Home Credit Default Risk (Open souce solution for Kaggle)\n",
    "\n",
    "August-2018\n",
    "\n",
    "Dear Kagglers,\n",
    "\n",
    "As you well know we share our work with the community for the benefit of all. We want to help those who are learning the ropes of data science get in the groove of things, we want to help those less organized make their code and process cleaner and finally we want those at the very top of the game to use our work (or parts of it) to develop state of the art solutions quicker and test the boundaries of what is possible for a given problem.\n",
    "\n",
    ":Authors: Kuba & Kamil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## What platforms are supported?\n",
    "\n",
    "Python3.5 and Ubuntu 16.04. more details can be found in requirements.txt\n",
    "\n",
    "(Ed: Also runs in approximately 3. hours in the following configuration:\n",
    "\n",
    "    Model Name:\tMac Pro\n",
    "    OS: High Sierra, version.10.6.13\n",
    "    Processor Name:\t12-Core Intel Xeon E5\n",
    "    Processor Speed:\t2.7 GHz\n",
    "    Total Number of Cores:\t12\n",
    "    L2 Cache (per Core):\t256 KB\n",
    "    L3 Cache:\t30 MB\n",
    "    Memory:\t64 GB\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How long does it take this solution to run?\n",
    "\n",
    "Finally, let me mention that end-to-end execution is something like 10-12h. Hence, indeed you may wait some time for the features to get computed. It happens here Step installment_payments_hand_crafted, fitting and transforming... \n",
    "\n",
    "Runtime heavily depends on your hardware. \n",
    "\n",
    "Please make sure that you are 100% compliant with our requirements.txt file. Differences in packages versions may lead to unexpected results :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  Is is possible to save features with your pipeline? \n",
    "I mean raw features, for train and test set, in the exact same shape as you feed them to your model?\n",
    "\n",
    ":Author: narsil (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Steppy Step object is designed to handle stuff like this. There are 3 flags that are particularly important to your problem:\n",
    "\n",
    "    persist_output = True\n",
    "    cache_output = True\n",
    "    load_persisted_output = False\n",
    "    \n",
    "In our case the Step that joins the features is called feature_joiner so go to this line and setup persist_output=True both during training and evaluation.\n",
    "\n",
    "Then you need to generate the features. I would suggest you do it in one go with something like this:\n",
    "\n",
    "    neptune run --config configs/neptune.yaml main.py train --pipeline_name lightGBM\n",
    "\n",
    "it will dump your features in the /YOUR_EXPERIMENT/outputs directory.\n",
    "\n",
    "Everything can be loaded with \n",
    "\n",
    "    sklearn.externals.joblib.load(filepath)\n",
    "\n",
    "The same thing can be done for the test set. Just run\n",
    "\n",
    "    neptune run --config configs/neptune.yaml main.py predict --pipeline_name lightGBM\n",
    "\n",
    "Now with our code we divide train/valid by default so if you want to have the entire train features and not train/valid you need to go to the pipeline_manager and change\n",
    "\n",
    "    train_data = {'application': {'X': train_data_split.drop(cfg.TARGET_COLUMNS, axis=1),\n",
    "                                  'y': train_data_split[cfg.TARGET_COLUMNS].values.reshape(-1),\n",
    "                                  'X_valid': valid_data_split.drop(cfg.TARGET_COLUMNS, axis=1),\n",
    "                                  'y_valid': valid_data_split[cfg.TARGET_COLUMNS].values.reshape(-1)\n",
    "                                  },\n",
    "to this\n",
    "\n",
    "    train_data = {'application': {'X': tables.application_train.drop(cfg.TARGET_COLUMNS, axis=1),\n",
    "                                  'y': tables.application_train[cfg.TARGET_COLUMNS].values.reshape(-1),\n",
    "                                  'X_valid':None,\n",
    "                                  'y_valid': None\n",
    "                                  },\n",
    "                                  \n",
    "It will most likely fail at training (because we need X_valid, y_valid) but is should generate the features correctly. If you have any trouble please let me know.\n",
    "\n",
    "\n",
    ":Author: Jakub Czakon (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  how do I convert a saved feature file into a dataframe\n",
    "\n",
    ":Author: incarnation (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "You can get data frame with all features by following code:\n",
    "\n",
    "    from sklearn.externals import joblib\n",
    "    df = joblib.load('path/to/your/feature_joiner')['features']\n",
    "\n",
    ":Author: Miłosz Michta (kaggle handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  where do I change the setting in a project to use multiple cpus?\n",
    "\n",
    "For example, the machine has 16 cpus, and if I want to use 8 cpu , how should I configure the setting in the project?\n",
    "\n",
    ":Author: Shize Su (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "num_workers in neptune.yaml is set by default to 1.\n",
    "\n",
    "If you want to run your training on 8 cpus, set num_workers: 8.\n",
    "\n",
    "(Ed: One cavet, is that most of the multi-cpu/core architectures, support 2 or more threads per cpu/core.  num_workers: should be set to thread count.  For example, Intel Core i7-7700K has 4 cores and 8 parellel threads.)\n",
    "\n",
    ":Author: Miłosz Michta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Where could we set (/change) the random seed for the kfold split? \n",
    "\n",
    " :Author: Shize Su (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "There is only one global random seed in pipeline_config.py: \n",
    "\n",
    "    RANDOM_SEED = 90210\n",
    "    \n",
    "To change random seed for only k-fold split, you can do this manually in pipeline_manager.py in _get_fold_generator function.\n",
    "\n",
    ":Author: Miłosz Michta (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## which setting in the project code should  be changed to avoid  state files over-writing?\n",
    "\n",
    ":Author: incarnation (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "\n",
    "There are 3 flags in the Step constructor that you need to consider:\n",
    "\n",
    "    persist_output: True\n",
    "    load_persisted_output: True\n",
    "    cache_output: True\n",
    "    \n",
    "If you don't want to ovewrite anything during eval/test just make sure to set \n",
    "    \n",
    "    perist_output: False\n",
    "    \n",
    "All the steps used are defined in the pipeline_blocks.py . More specifically you need to take care of the feature_joiner .\n",
    "\n",
    "It is also important to know that you can have a seperate experiment_dir for train and test so that you could just load your transformed features but change the classifier on top of it. In that case you would need to copy the experiment_dir/transformers to a new experiment directory. Also make sure to specify \n",
    "\n",
    "    clean_experiment_directory_before_training: 0 \n",
    "    \n",
    "in the neptune.yaml otherwise it will just remove everything from the experiment_dir . One last piece of the puzzle if you want to be steppy master is that if you have your lgbm trained in that folder steppy will simply load that model and transform it unless you pass \n",
    "    \n",
    "    force_fitting: True \n",
    "\n",
    "to the Step contractor for that step. Which means that running grid search or random search or simply retraining with different hyperparams you don't have to remove that lgbm transformer from experiment_dir/transformers but you can simply pass that flag and overwrite it.\n",
    "\n",
    ":Author: Jakub Czakon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How do you change models?\n",
    "\n",
    ":Author: Maximilian Hahn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "you can change that:\n",
    "\n",
    "    'random_forest': {'train': partial(sklearn_main,\n",
    "                                            ClassifierClass=RandomForestClassifier,\n",
    "                                            clf_name='random_forest',\n",
    "                                            train_mode=True),\n",
    "                     'inference': partial(sklearn_main,\n",
    "                                                ClassifierClass=RandomForestClassifier,\n",
    "                                                clf_name='random_forest',\n",
    "                                                train_mode=False)\n",
    "                    }\n",
    "to this:\n",
    "\n",
    "    'random_forest': partial(sklearn_main,\n",
    "                         ClassifierClass=RandomForestClassifier,\n",
    "                         clf_name='random_forest'),\n",
    "                         \n",
    "for the case of SKLearn RandomForestClassifier. For other models you can use a model from steppy-toolkit or write your own custom model using the closest model you can find from steppy-toolkit as a template.                       \n",
    "\n",
    ":Author: Miłosz Michta (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## is there a way to run Steppy or Neptune using Jupyter?\n",
    "\n",
    ":Author: Daniel Burrueco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "If you are doing it in python.\n",
    "\n",
    "    !python main.py -- train_evaluate_predict_cv --pipeline_name lightGBM\n",
    "\n",
    ":Author: William Green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "What is being executed are pipelines from main.py. In practice in means that you can create notebook in the repository root, import required libs and execute one of these pipelines.\n",
    "\n",
    "For example training pipeline is defined in the pipeline_manager.py file. Just make sure that you put correct paths to data.\n",
    "\n",
    ":Author: Kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  I run out of disk space. Is it possible to run with the cache turned off?\n",
    "\n",
    ":Author: Dromosys (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Set \n",
    "\n",
    "    cache_output=False\n",
    "    persist_output=False \n",
    "    load_persisted_output=False \n",
    "    \n",
    "in pipelines.py and pipeline_blocks.py\n",
    "\n",
    ":Author: Jakub Czakon (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  It looks like the script was designed to run on neptune only. I don't see the difference between Fast Track and Step by step installation guide.\n",
    "\n",
    ":Author: nlgn (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "Our code in neptune-agnostic, thus you can run it as Python script:\n",
    "\n",
    "    python main.py train_evaluate_predict --pipeline_name lightGBM.\n",
    "\n",
    "Full list of pipelines is here: lightGBM, XGBoost, random_forest, log_reg, svc. I'm still playing with XGBoost.\n",
    "\n",
    "My intention for Fast Track was to give three short points for User who can clone repo, install reqs, etc.\n",
    "\n",
    "\n",
    ":Author: kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Could you point me the right class structure and method names where to find save and load fold data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "If you want to read them in go:\n",
    "\n",
    "    from sklearn.externals import joblib\n",
    "    feature_dict = joblib.load('PATH/TO/FEATURE_JOINER/')\n",
    "    fetures = feature_dict['features']\n",
    "\n",
    ":Author: Jakub Czakon (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Is it possible to save target values via feature_joiner feature_joiner_valid while using cv? Or How can access cv target values and store?\n",
    "\n",
    ":Author: kkaczmarek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "You can adjust FeatureJoiner to do that:\n",
    "\n",
    "    class FeatureJoiner(BaseTransformer):\n",
    "    def __init__(self, use_nan_count=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.use_nan_count = use_nan_count\n",
    "\n",
    "    def transform(self, numerical_feature_list, categorical_feature_list, targets, **kwargs):\n",
    "        features = numerical_feature_list + categorical_feature_list\n",
    "        for feature in features:\n",
    "            feature.reset_index(drop=True, inplace=True)\n",
    "        features = pd.concat(features, axis=1).astype(np.float32)\n",
    "        if self.use_nan_count:\n",
    "            features['nan_count'] = features.isnull().sum(axis=1)\n",
    "\n",
    "        outputs = dict()\n",
    "        outputs['features'] = features\n",
    "        outputs['feature_names'] = list(features.columns)\n",
    "        outputs['categorical_features'] = self._get_feature_names(categorical_feature_list)\n",
    "        outputs['targets'] = targets\n",
    "        return outputs\n",
    "\n",
    "    def _get_feature_names(self, dataframes):\n",
    "        feature_names = []\n",
    "        for dataframe in dataframes:\n",
    "            try:\n",
    "                feature_names.extend(list(dataframe.columns))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                feature_names.append(dataframe.name)\n",
    "\n",
    "        return feature_names\n",
    "        \n",
    "Remember to change the pipeline_blocks accordingly.\n",
    "\n",
    "If you want it just for the adhoc purposes however I would simply dump the targets with _foldX suffix through pipeline_manager.py . For example:\n",
    "\n",
    "    for fold_id, (train_idx, valid_idx) in enumerate(fold_generator):\n",
    "    (train_data_split,\n",
    "     valid_data_split) = tables.application_train.iloc[train_idx], tables.application_train.iloc[valid_idx]\n",
    "\n",
    "     joblib.dump(train_data_split[cfg.TARGET_COLUMNS], 'train_target_fold_{}'.format(fold_id))\n",
    "\n",
    ":Author: Jakub Czakon (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  I am wondering: after running the code, where can I find the output, such as 'submission.csv'?\n",
    "\n",
    ":Author:  DKADKA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "It is placed in the experiment_directory that you specified in the yaml file.\n",
    "\n",
    ":Author: Kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  When I run any of the functions that include parallel apply the function gets hung up and does not move.\n",
    "\n",
    ":Author: benedic2 (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "I observed this effect for other versions of Pandas:\n",
    "\n",
    "1. make sure that you have version listed in the requirements file.\n",
    "1. Check CPU and memory utilization. Very likely everything is just fine. It just takes some time to extract features from files.\n",
    "1. If you are sure that you have issues with multiprocessing you can roll back to the standard Pandas. In such case you do not use parallel apply function. You simply change it to the operation on Pandas' group object. So something like groupobject.apply(func).reset_index(). This will do the same but with Pandas.\n",
    "\n",
    ":Author: kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Is the number of estimators set anywhere for the LGBM models?\n",
    "\n",
    ":Author: benedic2 (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Yes, we set it in the configuration files. Look for lgbm__number_boosting_rounds. \n",
    "\n",
    ":Author: kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How do you go about removing unimportant features? Do you remove simply remove all features with SHAP values below a certain threshold??\n",
    "\n",
    ":Author:  (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Actually, we are not removing any features. This could be really problematic. Take a look, that in our notebook we analyze data/model from fold_0 and features which have zero importance in this fold also have nonzero importance in others.\n",
    "\n",
    ":Author: Miłosz Michta (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Error:  from toolkit.sklearn_transformers.models import SklearnClassifier ModuleNotFoundError: No module named 'toolkit'\n",
    "\n",
    ":Author: Omid Safarzadeh (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "I think that you did not install steppy-toolkit==0.1.5. try this: \n",
    "\n",
    "    pip3 install steppy-toolkit==0.1.5.\n",
    "\n",
    ":Author: kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Is the command same for training after making adjustments to the parameters?\n",
    "\n",
    ":Author: William Green (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    " \n",
    "Remember to change the clean_experiment_directory in the neptune.yaml to False and force_fitting=True in the lightgbm Step. Running it again will load the features for each fold and train model on top of it.\n",
    "\n",
    ":Author: Jakub Czakon (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from TGS Salt Identification Challenge  (Open souce solution for Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Goals\n",
    "\n",
    "- establish solid benchmark for the competition,\n",
    "- make this competition more approachable by giving starter code and providing help via discussion forum, promote the idea of clean and extensible code for Kaggle competitions :) \n",
    "- In this topic... you will read about open solution updates, new ideas, experiments and comments. Feel invited to participate in building this.\n",
    "\n",
    "Have fun competing :) \n",
    "\n",
    ":Authors: Kuba & Kamil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## error: File \"open-solution-salt-identification-master/common_blocks/callbacks.py\",\n",
    "\n",
    "    line 150, in on_batch_end loss = loss.data.cpu().numpy()[0] IndexError: too many indices for array \n",
    "   \n",
    "  \n",
    ":Author: tommao (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Please make sure that you have torch==0.3.1. On the more general level, please make sure that you have all requirements is place: requirements.txt.\n",
    "\n",
    ":Author: Kamil (Kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## how to change the cost function?\n",
    "\n",
    " :Author: Ali Sharaf (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Go to the models.py and override the method set_loss() with whatever you like.\n",
    "\n",
    "For example I experimented a bit with this lovash loss and pretty much just passed the lovash_softmax from pytorch implementation there. \n",
    "\n",
    ":Author: Jakub Czakon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  'Error: Got unexpected extra argument (True)'\n",
    "\n",
    "used \n",
    "\n",
    "    python main.py -- train --pipeline_name unet --dev_mode True\n",
    "\n",
    ":Author: Tammao (kaggle handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "--dev_mode is a flag (it does not need any further arguments). You just need to put dev_mode without True.\n",
    "\n",
    "Therefore, if you need dev_mode go with this command: \n",
    "\n",
    "    python main.py -- train --pipeline_name unet --dev_mode\n",
    "\n",
    "If you do not need dev_mode use this one: \n",
    "\n",
    "    python main.py -- train --pipeline_name unet\n",
    "    \n",
    ":Author: kamil (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## how can I determine that is it using pretrained encoder or not?\n",
    "\n",
    "     U-Net parameters encoder: ResNet152\n",
    "\n",
    "It using ResNet152 as encoder. According to models.py there are a lot of PRETRAINED_NETWORKS. \n",
    "\n",
    ":Author: Tammao (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "There is a dictionary with models at the top of models.py and ResNet152 is one of the keys. So by selecting encoder in the neptune.yaml config you select that model from models.py\n",
    "\n",
    "\n",
    ":Author: Jakub Czakon (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## I run train() second time in one session it doesn't train, is it because already trained?\n",
    "\n",
    "Same result if I delete models from experiment folders\n",
    "\n",
    ":Author: Tammao (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "Models are trained so running again just loads the model and transforms/predicts on it. You can change the experiment_dir at the top of the main.py to run another model.\n",
    "\n",
    ":Author: Jakub Czakon (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How do I know which model, loss, etc. are being used?\n",
    "\n",
    ":Author: Daniel Möller (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "What we provide is source code that gives you good jump-start into the competition. It is worth to spend a while and analyze how do we think about the solution. Specifically, I recommend to git clone our source code and open it in your favorite IDE - I use PyCharm for coding. Then start with main.py and analyze the flow of the execution. This will give you good overview of what is happening. Regarding things that you mentioned:\n",
    "\n",
    "1. Some installation and execution help is here.\n",
    "2. model is UNet implemented in PyTorch.\n",
    "3. activation function\n",
    "\n",
    ":Author: kamil (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Is the train.csv the metadata.csv?\n",
    ":Author: William Green (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "\n",
    "No, you need to create it by running python main.py -- prepare_metadata or neptune run main.py prepare_metadata . Remember to specify the paths in the neptune.yaml first.\n",
    "\n",
    ":Author: Jakub Czakon (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##     neptune: Error: Invalid parameter 'prepare_metadata'. Parameter names must begin with double dash.\n",
    "When I tried to run it, I got the following response:\n",
    "\n",
    "    neptune: Executing in Offline Mode.\n",
    "\n",
    "    neptune: Error: Invalid parameter 'prepare_metadata'. Parameter names must begin with double dash.\n",
    "    \n",
    "What I am doing wrong?\n",
    "\n",
    ":Author: byoussin (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "Try with double dash:\n",
    "\n",
    "    python main.py -- prepare_metadata\n",
    "\n",
    ":Author: Jakub Czakon (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## when I run train, it gives the error  and the entire experiment directory vanishes, along with the meta_dir.\n",
    "\n",
    ":Author: arao(kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Answer\n",
    "You have your meta_dir inside of your experiment_dir and in the neptune.yaml you have option \n",
    "        \n",
    "        overwrite: 1\n",
    "        \n",
    "which means it cleans this experiment directory before doing anything else.\n",
    "\n",
    "My directory structure is something like this:\n",
    "\n",
    "project_dir:\n",
    "\n",
    "- data\n",
    "- meta\n",
    "- experiments\n",
    "    - exp_1\n",
    "    - exp_2\n",
    "    \n",
    "The most important part is that your meta directory should not be inside the workspace/experiment_dir.\n",
    "\n",
    ":Author: Jakub Czakon (kaggle handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-ship-detection\n",
    "https://github.com/neptune-ml/open-solution-ship-detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-value-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-googleai-object-detection\n",
    "https://github.com/neptune-ml/open-solution-googleai-object-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from Mapping Challenge\n",
    "https://www.crowdai.org/challenges/mapping-challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-value-prediction\n",
    "https://github.com/neptune-ml/open-solution-value-prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-cdiscount-starter\n",
    "https://github.com/neptune-ml/open-solution-cdiscount-starter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-talking-data\n",
    "https://github.com/neptune-ml/open-solution-talking-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-avito-demand-prediction\n",
    "https://github.com/neptune-ml/open-solution-avito-demand-prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q&A from open-solution-toxic-comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "62px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
